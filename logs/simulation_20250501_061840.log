Multi-UAV Simulation Log - Started at 20250501_061840
================================================================================

Configuration Parameters:
  scenario_width: 10.0
  scenario_height: 10.0
  uav_radius: 0.05
  target_radius: 0.05
  obstacle_radius_min: 0.04
  obstacle_radius_max: 0.1
  capture_distance: 1.2
  sensor_range: 0.4
  max_steps_per_episode: 50
  num_sensors: 24
  trajectory_length: 50
  time_step: 1
  uav_initial_velocity: 0.0
  uav_max_velocity: 0.13
  uav_max_acceleration: 0.05
  uav_mass: 0.5
  target_initial_velocity: 0.0
  target_max_velocity: 0.13
  target_max_acceleration: 0.05
  replay_buffer_size: 100000
  batch_size: 256
  pre_batch_size: 50
  gamma: 0.99
  tau: 0.001
  actor_lr: 0.0005
  critic_lr: 0.001
  num_episodes: 30000
  epsilon: 1.0
  epsilon_min: 0.01
  epsilon_decay: 0.98
  d_limit: 1.5
  curriculum_threshold: 5000
  curriculum_step_size: 1000
  curriculum_learning: {'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}, 'curriculum_steps': [{'step': 0, 'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}}, {'step': 1000, 'reward_weights': {'approach': 0.8, 'safety': 0.6, 'track': 0.4, 'encircle': 0.6, 'capture': 1.2, 'finish': 12.0}}, {'step': 2000, 'reward_weights': {'approach': 0.6, 'safety': 0.7, 'track': 0.5, 'encircle': 0.7, 'capture': 1.4, 'finish': 14.0}}, {'step': 3000, 'reward_weights': {'approach': 0.4, 'safety': 0.8, 'track': 0.6, 'encircle': 0.8, 'capture': 1.6, 'finish': 16.0}}, {'step': 4000, 'reward_weights': {'approach': 0.2, 'safety': 0.9, 'track': 0.7, 'encircle': 0.9, 'capture': 1.8, 'finish': 18.0}}]}
  correlation_weights: {'sigma1': 100, 'sigma2': 2, 'sigma3': 5}
  reward_weights: {'approach': 1.0, 'safety': 1.0, 'track': 1.0, 'encircle': 1.0, 'capture': 1.0, 'finish': 1.0}

Episode 0 - Started (Seed: 7720)
  Initial Positions:
    seed: 7720
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 7720)
  Initial Positions:
    uavs: [[0.9892243696116644, 3.0206141956915253], [5.225804921669235, 0.5219345224539033], [0.49843232069260024, 5.549543018375143]]
    target: [5.421238999371731, 5.112371209755988]
    obstacles: {'positions': [[3.6035664576583324, 3.8595171247889413], [8.7921531981583, 4.086779088565228], [2.839640698357858, 8.85220397605203]], 'radii': [0.057117329549446164, 0.06041272882474945, 0.048408268043133584]}
Episode 0 - Started (Seed: 7720)
  Initial Positions:
    seed: 7720
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 7720)
  Initial Positions:
    uavs: [[0.9892243696116644, 3.0206141956915253], [5.225804921669235, 0.5219345224539033], [0.49843232069260024, 5.549543018375143]]
    target: [5.421238999371731, 5.112371209755988]
    obstacles: {'positions': [[3.6035664576583324, 3.8595171247889413], [8.7921531981583, 4.086779088565228], [2.839640698357858, 8.85220397605203]], 'radii': [0.057117329549446164, 0.06041272882474945, 0.048408268043133584]}
Episode 10, Step episode:
  Actions: [array([0.43548572, 1.        ], dtype=float32), array([-0.4156361 ,  0.27518237], dtype=float32), array([ 1.       , -0.5301364], dtype=float32)]
  Rewards: [0.6734009465693266, 0.003546314741429968, 0.5664817476381482]
Episode 20, Step episode:
  Actions: [array([ 1.        , -0.25851697], dtype=float32), array([ 0.30893606, -0.1681315 ], dtype=float32), array([1., 1.], dtype=float32)]
  Rewards: [-1.1858819135393415, -0.048451235074203514, 0.5602415326291456]
Episode 30, Step episode:
  Actions: [array([1.        , 0.10809131], dtype=float32), array([ 0.84436244, -0.04410183], dtype=float32), array([ 0.6084944, -1.       ], dtype=float32)]
  Rewards: [-1.2690544125694048, -0.13009500102520627, 0.5262406830499649]
Episode 37, Step episode:
  Actions: [array([-0.7335836 , -0.14151296], dtype=float32), array([-1.       ,  0.6962015], dtype=float32), array([0.4118353, 1.       ], dtype=float32)]
  Rewards: [-1.0336219411736347, -0.1812365393558742, 0.503115093721703]
Episode 40, Step episode:
  Actions: [array([-1.        , -0.45332262], dtype=float32), array([ 0.3982853, -1.       ], dtype=float32), array([0.12379317, 1.        ], dtype=float32)]
  Rewards: [0.47224629046734073, -0.5763170688363557, 0.5083707476988877]
Episode 41, Step episode:
  Actions: [array([-1., -1.], dtype=float32), array([0.46181872, 0.28263   ], dtype=float32), array([-0.4726491 ,  0.47618508], dtype=float32)]
  Rewards: [0.5229385075019297, -0.3632345460725619, 0.5118654256277202]
Episode 50, Step episode:
  Actions: [array([-0.259507 ,  0.6510286], dtype=float32), array([-1.       ,  0.6328992], dtype=float32), array([ 1., -1.], dtype=float32)]
  Rewards: [0.5057939308749382, -1.0821052606507953, 0.5736966780408346]
Episode episode - Completed
  Reward: -0.0026
  Success: False
  Steps: 50
  ------------------------------------------------------------

Episode 1 - Started (Seed: 7720)
  Initial Positions:
    seed: 7720
ERROR: Curriculum learning: Episode 1, placing target closer to UAVs (min_distance=0.25)
Episode 1 - Started (Seed: 7720)
  Initial Positions:
    uavs: [[0.9892243696116644, 3.0206141956915253], [5.225804921669235, 0.5219345224539033], [0.49843232069260024, 5.549543018375143]]
    target: [5.421238999371731, 5.112371209755988]
    obstacles: {'positions': [[3.6035664576583324, 3.8595171247889413], [8.7921531981583, 4.086779088565228], [2.839640698357858, 8.85220397605203]], 'radii': [0.057117329549446164, 0.06041272882474945, 0.048408268043133584]}
Episode 10, Step episode:
  Actions: [array([-0.9381541, -1.       ], dtype=float32), array([-1.        ,  0.31139085], dtype=float32), array([0.84192526, 1.        ], dtype=float32)]
  Rewards: [0.6733216003870379, 0.00536319895660986, 0.5663077136266372]
