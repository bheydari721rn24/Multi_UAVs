Multi-UAV Simulation Log - Started at 20250501_062326
================================================================================

Configuration Parameters:
  scenario_width: 10.0
  scenario_height: 10.0
  uav_radius: 0.05
  target_radius: 0.05
  obstacle_radius_min: 0.04
  obstacle_radius_max: 0.1
  capture_distance: 1.2
  sensor_range: 0.4
  max_steps_per_episode: 50
  num_sensors: 24
  trajectory_length: 50
  time_step: 1
  uav_initial_velocity: 0.0
  uav_max_velocity: 0.13
  uav_max_acceleration: 0.05
  uav_mass: 0.5
  target_initial_velocity: 0.0
  target_max_velocity: 0.13
  target_max_acceleration: 0.05
  replay_buffer_size: 100000
  batch_size: 256
  pre_batch_size: 50
  gamma: 0.99
  tau: 0.001
  actor_lr: 0.0005
  critic_lr: 0.001
  num_episodes: 30000
  epsilon: 1.0
  epsilon_min: 0.01
  epsilon_decay: 0.98
  d_limit: 1.5
  curriculum_threshold: 5000
  curriculum_step_size: 1000
  curriculum_learning: {'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}, 'curriculum_steps': [{'step': 0, 'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}}, {'step': 1000, 'reward_weights': {'approach': 0.8, 'safety': 0.6, 'track': 0.4, 'encircle': 0.6, 'capture': 1.2, 'finish': 12.0}}, {'step': 2000, 'reward_weights': {'approach': 0.6, 'safety': 0.7, 'track': 0.5, 'encircle': 0.7, 'capture': 1.4, 'finish': 14.0}}, {'step': 3000, 'reward_weights': {'approach': 0.4, 'safety': 0.8, 'track': 0.6, 'encircle': 0.8, 'capture': 1.6, 'finish': 16.0}}, {'step': 4000, 'reward_weights': {'approach': 0.2, 'safety': 0.9, 'track': 0.7, 'encircle': 0.9, 'capture': 1.8, 'finish': 18.0}}]}
  correlation_weights: {'sigma1': 100, 'sigma2': 2, 'sigma3': 5}
  reward_weights: {'approach': 1.0, 'safety': 1.0, 'track': 1.0, 'encircle': 1.0, 'capture': 1.0, 'finish': 1.0}

Episode 0 - Started (Seed: 8006)
  Initial Positions:
    seed: 8006
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 8006)
  Initial Positions:
    uavs: [[4.735673278446918, 4.01940982993792], [6.07984546394219, 2.486584082138332], [3.3979327958640666, 7.229258274747868]]
    target: [1.4073085108762826, 1.2373390773189092]
    obstacles: {'positions': [[4.846126272200007, 0.39985723738375367], [8.151435681528334, 0.5212076190285613], [3.7601487416988224, 5.598946577292054]], 'radii': [0.08822340717553032, 0.08640007264891283, 0.048449729986566395]}
Episode 0 - Started (Seed: 8006)
  Initial Positions:
    seed: 8006
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 8006)
  Initial Positions:
    uavs: [[4.735673278446918, 4.01940982993792], [6.07984546394219, 2.486584082138332], [3.3979327958640666, 7.229258274747868]]
    target: [1.4073085108762826, 1.2373390773189092]
    obstacles: {'positions': [[4.846126272200007, 0.39985723738375367], [8.151435681528334, 0.5212076190285613], [3.7601487416988224, 5.598946577292054]], 'radii': [0.08822340717553032, 0.08640007264891283, 0.048449729986566395]}
Episode 10, Step episode:
  Actions: [array([-0.8025787,  1.       ], dtype=float32), array([1.        , 0.17039925], dtype=float32), array([ 0.47775644, -0.3523054 ], dtype=float32)]
  Rewards: [-1.4632005735776348, -1.4909076483239845, -1.262850607224005]
Episode 20, Step episode:
  Actions: [array([0.12374835, 0.14114234], dtype=float32), array([ 0.29565895, -0.16914608], dtype=float32), array([-0.6040841, -0.7393391], dtype=float32)]
  Rewards: [-1.576934506001773, -1.5967846280383682, -1.4320576791267712]
Episode 30, Step episode:
  Actions: [array([-0.38749033,  0.46024373], dtype=float32), array([0.36460054, 1.        ], dtype=float32), array([-0.88611734, -0.93694735], dtype=float32)]
  Rewards: [-1.6409973249320033, -1.6504828740705104, -1.5239475745169746]
Episode 34, Step episode:
  Actions: [array([-0.5189072, -0.919255 ], dtype=float32), array([1.        , 0.08744441], dtype=float32), array([-0.14699157,  0.30540985], dtype=float32)]
  Rewards: [-1.692921706450059, -1.6436274750958084, -1.5930682302371943]
Episode 40, Step episode:
  Actions: [array([ 0.40805778, -1.        ], dtype=float32), array([ 0.15009557, -1.        ], dtype=float32), array([ 1., -1.], dtype=float32)]
  Rewards: [-1.7422296563034607, -0.2936461012479025, -1.653353954390435]
Episode 46, Step episode:
  Actions: [array([0.39352298, 0.3050114 ], dtype=float32), array([-0.46982703, -0.51861507], dtype=float32), array([ 0.3282509, -1.       ], dtype=float32)]
  Rewards: [-2.150466352318937, -0.38023865650892036, -1.6531044420573449]
Episode 50, Step episode:
  Actions: [array([-1.        , -0.41622412], dtype=float32), array([-0.78743714, -0.14433326], dtype=float32), array([-0.28541213, -1.        ], dtype=float32)]
  Rewards: [-0.6793575730213717, -0.40792426224383743, -1.7627890725526643]
Episode episode - Completed
  Reward: -2.8501
  Success: False
  Steps: 50
  ------------------------------------------------------------

Episode 1 - Started (Seed: 8006)
  Initial Positions:
    seed: 8006
ERROR: Curriculum learning: Episode 1, placing target closer to UAVs (min_distance=0.25)
Episode 1 - Started (Seed: 8006)
  Initial Positions:
    uavs: [[4.735673278446918, 4.01940982993792], [6.07984546394219, 2.486584082138332], [3.3979327958640666, 7.229258274747868]]
    target: [1.4073085108762826, 1.2373390773189092]
    obstacles: {'positions': [[4.846126272200007, 0.39985723738375367], [8.151435681528334, 0.5212076190285613], [3.7601487416988224, 5.598946577292054]], 'radii': [0.08822340717553032, 0.08640007264891283, 0.048449729986566395]}
