Multi-UAV Simulation Log - Started at 20250501_062157
================================================================================

Configuration Parameters:
  scenario_width: 10.0
  scenario_height: 10.0
  uav_radius: 0.05
  target_radius: 0.05
  obstacle_radius_min: 0.04
  obstacle_radius_max: 0.1
  capture_distance: 1.2
  sensor_range: 0.4
  max_steps_per_episode: 50
  num_sensors: 24
  trajectory_length: 50
  time_step: 1
  uav_initial_velocity: 0.0
  uav_max_velocity: 0.13
  uav_max_acceleration: 0.05
  uav_mass: 0.5
  target_initial_velocity: 0.0
  target_max_velocity: 0.13
  target_max_acceleration: 0.05
  replay_buffer_size: 100000
  batch_size: 256
  pre_batch_size: 50
  gamma: 0.99
  tau: 0.001
  actor_lr: 0.0005
  critic_lr: 0.001
  num_episodes: 30000
  epsilon: 1.0
  epsilon_min: 0.01
  epsilon_decay: 0.98
  d_limit: 1.5
  curriculum_threshold: 5000
  curriculum_step_size: 1000
  curriculum_learning: {'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}, 'curriculum_steps': [{'step': 0, 'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}}, {'step': 1000, 'reward_weights': {'approach': 0.8, 'safety': 0.6, 'track': 0.4, 'encircle': 0.6, 'capture': 1.2, 'finish': 12.0}}, {'step': 2000, 'reward_weights': {'approach': 0.6, 'safety': 0.7, 'track': 0.5, 'encircle': 0.7, 'capture': 1.4, 'finish': 14.0}}, {'step': 3000, 'reward_weights': {'approach': 0.4, 'safety': 0.8, 'track': 0.6, 'encircle': 0.8, 'capture': 1.6, 'finish': 16.0}}, {'step': 4000, 'reward_weights': {'approach': 0.2, 'safety': 0.9, 'track': 0.7, 'encircle': 0.9, 'capture': 1.8, 'finish': 18.0}}]}
  correlation_weights: {'sigma1': 100, 'sigma2': 2, 'sigma3': 5}
  reward_weights: {'approach': 1.0, 'safety': 1.0, 'track': 1.0, 'encircle': 1.0, 'capture': 1.0, 'finish': 1.0}

Episode 0 - Started (Seed: 7917)
  Initial Positions:
    seed: 7917
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 7917)
  Initial Positions:
    uavs: [[3.915121532157742, 4.4470038425068905], [5.710875977657733, 3.4653685740885596], [3.666780111301274, 5.361206588949505]]
    target: [6.114562278509365, 2.5993269990114403]
    obstacles: {'positions': [[0.8332836038860187, 2.54046926898752], [8.653710184217735, 3.056085546163993], [2.6143577467479164, 9.604346617367653]], 'radii': [0.06805077411941843, 0.06760167888687574, 0.06944288398089839]}
Episode 0 - Started (Seed: 7917)
  Initial Positions:
    seed: 7917
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 7917)
  Initial Positions:
    uavs: [[3.915121532157742, 4.4470038425068905], [5.710875977657733, 3.4653685740885596], [3.666780111301274, 5.361206588949505]]
    target: [6.114562278509365, 2.5993269990114403]
    obstacles: {'positions': [[0.8332836038860187, 2.54046926898752], [8.653710184217735, 3.056085546163993], [2.6143577467479164, 9.604346617367653]], 'radii': [0.06805077411941843, 0.06760167888687574, 0.06944288398089839]}
Episode 10, Step episode:
  Actions: [array([-0.22064157,  1.        ], dtype=float32), array([0.89053917, 1.        ], dtype=float32), array([1.        , 0.28778362], dtype=float32)]
  Rewards: [-0.19385230445914514, -0.7927465739366089, -0.22855520030787196]
Episode 20, Step episode:
  Actions: [array([-0.71518993,  0.81366616], dtype=float32), array([-1.        ,  0.12798062], dtype=float32), array([-0.52643526,  1.        ], dtype=float32)]
  Rewards: [-0.6581396856448037, -1.0282635649606893, -0.6282930220583023]
Episode 30, Step episode:
  Actions: [array([-1.        ,  0.19923496], dtype=float32), array([ 1.        , -0.84017587], dtype=float32), array([0.13842018, 0.08355236], dtype=float32)]
  Rewards: [-0.9128018300878431, -1.2023743675095109, -0.853517230163926]
Episode 37, Step episode:
  Actions: [array([1., 1.], dtype=float32), array([-0.45668122,  1.        ], dtype=float32), array([ 0.37504867, -0.8631966 ], dtype=float32)]
  Rewards: [-1.1028231894991345, -1.8200768359203419, -1.034260264332651]
Episode 40, Step episode:
  Actions: [array([ 0.27968833, -0.6123378 ], dtype=float32), array([ 0.48057637, -0.16904448], dtype=float32), array([-0.1340376 , -0.10092841], dtype=float32)]
  Rewards: [-1.181566628620823, -0.7659911061840243, -1.1176120432545575]
Episode 50, Step episode:
  Actions: [array([0.8045027 , 0.31239995], dtype=float32), array([-0.92980677,  0.3683108 ], dtype=float32), array([0.68220514, 1.        ], dtype=float32)]
  Rewards: [-1.9976158512119904, -0.6723741562291546, -1.3621748030722487]
Episode episode - Completed
  Reward: -4.0322
  Success: False
  Steps: 50
  ------------------------------------------------------------

Episode 1 - Started (Seed: 7917)
  Initial Positions:
    seed: 7917
ERROR: Curriculum learning: Episode 1, placing target closer to UAVs (min_distance=0.25)
Episode 1 - Started (Seed: 7917)
  Initial Positions:
    uavs: [[3.915121532157742, 4.4470038425068905], [5.710875977657733, 3.4653685740885596], [3.666780111301274, 5.361206588949505]]
    target: [6.114562278509365, 2.5993269990114403]
    obstacles: {'positions': [[0.8332836038860187, 2.54046926898752], [8.653710184217735, 3.056085546163993], [2.6143577467479164, 9.604346617367653]], 'radii': [0.06805077411941843, 0.06760167888687574, 0.06944288398089839]}
