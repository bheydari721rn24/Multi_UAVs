Multi-UAV Simulation Log - Started at 20250501_064113
================================================================================

Configuration Parameters:
  scenario_width: 10.0
  scenario_height: 10.0
  uav_radius: 0.05
  target_radius: 0.05
  obstacle_radius_min: 0.04
  obstacle_radius_max: 0.1
  capture_distance: 1.2
  sensor_range: 0.4
  max_steps_per_episode: 50
  num_sensors: 24
  trajectory_length: 50
  time_step: 1
  uav_initial_velocity: 0.0
  uav_max_velocity: 0.13
  uav_max_acceleration: 0.05
  uav_mass: 0.5
  target_initial_velocity: 0.0
  target_max_velocity: 0.13
  target_max_acceleration: 0.05
  replay_buffer_size: 100000
  batch_size: 256
  pre_batch_size: 50
  gamma: 0.99
  tau: 0.001
  actor_lr: 0.0005
  critic_lr: 0.001
  num_episodes: 30000
  epsilon: 1.0
  epsilon_min: 0.01
  epsilon_decay: 0.98
  d_limit: 1.5
  curriculum_threshold: 5000
  curriculum_step_size: 1000
  curriculum_learning: {'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}, 'curriculum_steps': [{'step': 0, 'reward_weights': {'approach': 1.0, 'safety': 0.5, 'track': 0.3, 'encircle': 0.5, 'capture': 1.0, 'finish': 10.0}}, {'step': 1000, 'reward_weights': {'approach': 0.8, 'safety': 0.6, 'track': 0.4, 'encircle': 0.6, 'capture': 1.2, 'finish': 12.0}}, {'step': 2000, 'reward_weights': {'approach': 0.6, 'safety': 0.7, 'track': 0.5, 'encircle': 0.7, 'capture': 1.4, 'finish': 14.0}}, {'step': 3000, 'reward_weights': {'approach': 0.4, 'safety': 0.8, 'track': 0.6, 'encircle': 0.8, 'capture': 1.6, 'finish': 16.0}}, {'step': 4000, 'reward_weights': {'approach': 0.2, 'safety': 0.9, 'track': 0.7, 'encircle': 0.9, 'capture': 1.8, 'finish': 18.0}}]}
  correlation_weights: {'sigma1': 100, 'sigma2': 2, 'sigma3': 5}
  reward_weights: {'approach': 1.0, 'safety': 1.0, 'track': 1.0, 'encircle': 1.0, 'capture': 1.0, 'finish': 1.0}

Episode 0 - Started (Seed: 9073)
  Initial Positions:
    seed: 9073
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 9073)
  Initial Positions:
    uavs: [[1.2310553353328446, 0.4172228595531442], [8.168839584134727, 0.7328035613766403], [1.937112858896772, 7.865846633073368]]
    target: [8.438190320950547, 1.4262777908374342]
    obstacles: {'positions': [[1.9034223175415765, 2.086617594483704], [6.478539211767554, 2.6575341001070503], [1.3681340233082566, 6.297822912069021]], 'radii': [0.08925354271852351, 0.08719180875342336, 0.07092161644510778]}
Episode 0 - Started (Seed: 9073)
  Initial Positions:
    seed: 9073
ERROR: Curriculum learning: Episode 0, placing target closer to UAVs (min_distance=0.25)
Episode 0 - Started (Seed: 9073)
  Initial Positions:
    uavs: [[1.2310553353328446, 0.4172228595531442], [8.168839584134727, 0.7328035613766403], [1.937112858896772, 7.865846633073368]]
    target: [8.438190320950547, 1.4262777908374342]
    obstacles: {'positions': [[1.9034223175415765, 2.086617594483704], [6.478539211767554, 2.6575341001070503], [1.3681340233082566, 6.297822912069021]], 'radii': [0.08925354271852351, 0.08719180875342336, 0.07092161644510778]}
Episode 10, Step episode:
  Actions: [array([-0.99083287, -1.        ], dtype=float32), array([ 0.09775393, -0.5776384 ], dtype=float32), array([ 0.35386434, -0.7824807 ], dtype=float32)]
  Rewards: [0.42820814459685097, -0.6384960135014537, -0.03688319093306991]
Episode 17, Step episode:
  Actions: [array([-1.       ,  0.7783298], dtype=float32), array([0.08174204, 0.2769486 ], dtype=float32), array([ 0.8198304, -1.       ], dtype=float32)]
  Rewards: [2.0039381172906063, 1.522676672398673, 1.915783732107374]
Episode 20, Step episode:
  Actions: [array([ 0.5283711, -0.2613157], dtype=float32), array([-1.,  1.], dtype=float32), array([-1., -1.], dtype=float32)]
  Rewards: [2.525221543862327, 2.632243400808462, 2.179732518517388]
Episode 30, Step episode:
  Actions: [array([-0.86025417, -0.6217651 ], dtype=float32), array([-1.        ,  0.09384892], dtype=float32), array([ 1., -1.], dtype=float32)]
  Rewards: [2.3806742659551126, 2.4203762631975962, 1.5867382795725549]
Episode 40, Step episode:
  Actions: [array([ 0.3160834 , -0.99677813], dtype=float32), array([-1.        ,  0.87496024], dtype=float32), array([0.25360006, 0.11257978], dtype=float32)]
  Rewards: [0.02264483246896598, 0.36271134084608425, -0.6165940081393539]
Episode 50, Step episode:
  Actions: [array([-0.0445282, -0.4815331], dtype=float32), array([-1.        , -0.49440095], dtype=float32), array([ 1., -1.], dtype=float32)]
  Rewards: [-0.7955683693036896, -0.06094798367619547, 0.11811976934457019]
Episode episode - Completed
  Reward: -0.7384
  Success: False
  Steps: 50
  ------------------------------------------------------------

Episode 1 - Started (Seed: 9073)
  Initial Positions:
    seed: 9073
ERROR: Curriculum learning: Episode 1, placing target closer to UAVs (min_distance=0.25)
Episode 1 - Started (Seed: 9073)
  Initial Positions:
    uavs: [[1.2310553353328446, 0.4172228595531442], [8.168839584134727, 0.7328035613766403], [1.937112858896772, 7.865846633073368]]
    target: [8.438190320950547, 1.4262777908374342]
    obstacles: {'positions': [[1.9034223175415765, 2.086617594483704], [6.478539211767554, 2.6575341001070503], [1.3681340233082566, 6.297822912069021]], 'radii': [0.08925354271852351, 0.08719180875342336, 0.07092161644510778]}
